# Aprendizaje no supervisadoEn unsupervised learning no tenemos variable respuesta.Necesitamos agrupar registros que se parecen entre sí, aunque no me vaya a decir qué son realmente. ## Tipos**Clustering*** K-means.* Hierarchical Clustering.* Probabilistic Clustering.**Data Compression*** Principal Component Analysis.* Singular Value Decomposition (u otras factorizaciones de matrices).* t-Distributed Stochastic Neighbor Embedding. **Unsupervised Deep Learning*** Autoencoders.* Anomaly detection.##Conceptos ### Métrica (o distancia)Una métrica 𝑑:𝑋×𝑋→ (0,Infinito)  es una función que satisface las siguientes condiciones para cada 𝑥, 𝑦∈𝑋:*𝑑 𝑥,𝑦 ≥0, no negativa.*𝑑 𝑥,𝑦 =0⟺𝑥=𝑦, identidad indecirnible.*𝑑 𝑥,𝑦 =𝑑 𝑦,𝑥 , simetría.* 𝑑 𝑥,𝑧 ≤𝑑 𝑥,𝑦 + 𝑑 𝑦,𝑧 , desigualdad triangular.Tipos:* Distancia euclideana.* Distancia de Minkowski.* Distancia de Manhattan.* Distancia de Levenshtein.* Distancia del infimo y supremo.### ScalingTenemos un dataset con dos variables.- Pesos: que va de 0 a 120. - Número de hijo: que va de 0 a 10. Si yo eso lo represento en un plano X,Y, me salen que un tío que tiene 60 k y 0 hijos se parece mucho a otro que pesa 60 y tiene 10, Hay que normalizar eso, para que todas las variables estén entre 0 y 1. **Métodos de normalización**![f1](media/formula1.png) ![f1](media/formula12png) ## K-MeansMuy fácil de inteprestar. Muy utilizado.## Hierarchical ClusteringUn poco más difícil de entender. Henry nunca lo ha usado para datos reales## Dimensionaliadades altas, como enfrentarnos a ellas. Por ejemplo, Como normalmente 